{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MusicLSTM",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XMw9zxMrYOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "#!wget http://www.gutenberg.org/files/100/100-0.txt\n",
        "!ls\n",
        "!apt-get install midicsv timidity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czMqXmrcv-XR",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWKQcSNgPPeu",
        "colab_type": "code",
        "outputId": "246642dc-f24c-4965-ca2c-228a2bc7c6ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib import rnn\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "\n",
        "#Vars\n",
        "steps = 64\n",
        "n_hidden = 1024\n",
        "n_layers = 1\n",
        "n_input = 129\n",
        "learning_rate = 0.0003\n",
        "n_classes = 129\n",
        "batch_size = 128\n",
        "iterations = 25000\n",
        "targetloss = 0.05\n",
        "currentpath = \"/content/drive/My Drive/Programming/rnn/MusicRNN/\"\n",
        "textfile = open(currentpath + \"/midis/text.txt\", \"r\")\n",
        "outfile = open(currentpath + \"out.txt\", \"w\")\n",
        "filecont = list(map(int, textfile.read().replace(\"\\n\", \"128 \").split()))\n",
        "flength = len(filecont)\n",
        "\n",
        "tf.reset_default_graph()\n",
        "tf.logging.set_verbosity(tf.logging.ERROR) \n",
        "    \n",
        "#FUNCTIONS\n",
        "#Structure of NN\n",
        "class RNN:\n",
        "    def __init__(self, units, goIn, weights, biases):\n",
        "        self.lstm_layer = rnn.MultiRNNCell([rnn.BasicLSTMCell(units) for i in range(n_layers)])\n",
        "        self.outputs, self.state = rnn.static_rnn(self.lstm_layer, goIn, dtype = \"float32\")\n",
        "        for i in range(n_layers-1):\n",
        "            self.outputs = [tf.nn.relu(tf.matmul(self.outputs[j], weights[\"hid\"][i]) + biases[\"hid\"][i]) for j in range(len(self.outputs))]\n",
        "            self.outputs = tf.nn.dropout(self.outputs, keep_prob)\n",
        "    def p(self, x, keep_prob):\n",
        "        return tf.matmul(self.outputs[x], weights[\"out\"][0]) + biases[\"out\"][0]\n",
        "\n",
        "def charnum(c):\n",
        "    return int(c)\n",
        "\n",
        "def numtolst(n):\n",
        "    lst = [0] * n_input\n",
        "    lst[n] = 1\n",
        "    return lst\n",
        "\n",
        "def lisnum(n):\n",
        "    o = []\n",
        "    for i in range(len(n)):\n",
        "        o.append([])\n",
        "        for j in range(len(n[i])):\n",
        "            for k in range(len(n[i][j])):\n",
        "                if n[i][j][k] == 1:\n",
        "                    o[i].append(k)\n",
        "    return o\n",
        "\n",
        "def getBatch():\n",
        "    outputd = []\n",
        "    outputl = []\n",
        "    for i in range(batch_size):\n",
        "        l = random.randint(0, flength - steps - 1);\n",
        "        seed = []\n",
        "        for j in range(steps):\n",
        "            seed.append(numtolst(charnum(filecont[l + j])))\n",
        "        outputd.append(list(seed))\n",
        "        outputl.append(numtolst(charnum(filecont[l + steps])))\n",
        "    return np.asarray(outputd), np.asarray(outputl)\n",
        "\n",
        "print(\"File length is \" + str(flength))\n",
        "\n",
        "weights = {\n",
        "    \"hid\" : [tf.Variable(tf.random_normal([n_hidden, n_hidden])), tf.Variable(tf.random_normal([n_hidden, n_hidden])),\n",
        "             tf.Variable(tf.random_normal([n_hidden, n_hidden])), tf.Variable(tf.random_normal([n_hidden, n_hidden]))],\n",
        "    \"out\" : [tf.Variable(tf.random_normal([n_hidden, n_classes]))]\n",
        "}\n",
        "biases = {\n",
        "    \"hid\" : [tf.Variable(tf.random_normal([n_hidden])), tf.Variable(tf.random_normal([n_hidden])),\n",
        "             tf.Variable(tf.random_normal([n_hidden])), tf.Variable(tf.random_normal([n_hidden]))],\n",
        "    \"out\" : [tf.Variable(tf.random_normal([n_classes]))]\n",
        "}\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "inp = tf.placeholder(\"float\", [None, steps, n_input])\n",
        "\n",
        "lab = tf.placeholder(\"float\", [None, n_classes])\n",
        "\n",
        "inpu = tf.unstack(inp, steps, 1)\n",
        "\n",
        "lstm = RNN(n_hidden, inpu, weights, biases)\n",
        "\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
        "    logits = lstm.p(-1, keep_prob), labels = lab))\n",
        "\n",
        "optimize = tf.train.RMSPropOptimizer(learning_rate = learning_rate).minimize(loss)\n",
        "\n",
        "correct = tf.equal(tf.argmax(lstm.p(-1, keep_prob), 1), tf.argmax(lab, 1))\n",
        "\n",
        "answer = tf.argmax(lstm.p(-1, keep_prob), 1)\n",
        "\n",
        "conf = lstm.p(-1, keep_prob)\n",
        "\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "\n",
        "saver = tf.train.Saver(tf.trainable_variables())\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Run NN\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    i = 1\n",
        "    try:\n",
        "        print(\"Loading save\")\n",
        "        saver.restore(sess, currentpath + \"weights/weights.ckpt\")\n",
        "    except:\n",
        "        print(\"No save found\")\n",
        "    while i <= iterations:\n",
        "        print(\"Getting Batches...\")\n",
        "        batch_in, batch_lab = getBatch()\n",
        "        #print lisnum(batch_in)\n",
        "        batch_in = batch_in.reshape((batch_size, steps, n_input)) #get input\n",
        "        fd = {inp: batch_in, lab: batch_lab, keep_prob: 0.3}\n",
        "        print(\"Training...\")\n",
        "        sess.run(optimize, fd)\n",
        "        print(\"Calculating Accuracy...\")\n",
        "        a = sess.run(accuracy, fd)\n",
        "        print (\"Calculating Loss...\")\n",
        "        l = sess.run(loss, fd)\n",
        "        #print \"Calculating Answers...\"\n",
        "        #ans = sess.run(answer, feed_dict={inp: batch_in, lab: batch_lab})\n",
        "        #c = sess.run(conf, feed_dict={inp: batch_in, lab: batch_lab})\n",
        "        print(\"Iteration \" + str(i))\n",
        "        print(\"Accuracy  \" + str(a)) #display data\n",
        "        print(\"Loss      \" + str(l))\n",
        "        #print \"Answer    \" + str(ans)\n",
        "        #print \"Conf      \" + str(c)\n",
        "        #print \"ANS: \" + str(sess.run(answer, feed_dict={inp: np.asarray(batch_in), lab: batch_lab}))\n",
        "        print(\"\\n\\n\\n\")\n",
        "        if i % 4 == 0:\n",
        "            spot = saver.save(sess, currentpath + \"weights/weights.ckpt\")\n",
        "            print(spot)\n",
        "\n",
        "        i += 1  \n",
        "        if l <= targetloss:\n",
        "            spot = saver.save(sess, currentpath + \"weights/weights.ckpt\")\n",
        "            print(spot)\n",
        "            break;\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Accuracy...\n",
            "Calculating Loss...\n",
            "Iteration 2499\n",
            "Accuracy  0.9140625\n",
            "Loss      0.35423332\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Getting Batches...\n",
            "Training...\n",
            "Calculating Accuracy...\n",
            "Calculating Loss...\n",
            "Iteration 2500\n",
            "Accuracy  0.9453125\n",
            "Loss      0.2228224\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "/content/drive/My Drive/Programming/rnn/MusicRNN/weights/weights.ckpt\n",
            "Getting Batches...\n",
            "Training...\n",
            "Calculating Accuracy...\n",
            "Calculating Loss...\n",
            "Iteration 2501\n",
            "Accuracy  0.9375\n",
            "Loss      0.27345905\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Getting Batches...\n",
            "Training...\n",
            "Calculating Accuracy...\n",
            "Calculating Loss...\n",
            "Iteration 2502\n",
            "Accuracy  0.9609375\n",
            "Loss      0.2058753\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Getting Batches...\n",
            "Training...\n",
            "Calculating Accuracy...\n",
            "Calculating Loss...\n",
            "Iteration 2503\n",
            "Accuracy  0.953125\n",
            "Loss      0.22797267\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Getting Batches...\n",
            "Training...\n",
            "Calculating Accuracy...\n",
            "Calculating Loss...\n",
            "Iteration 2504\n",
            "Accuracy  0.9453125\n",
            "Loss      0.24231051\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "/content/drive/My Drive/Programming/rnn/MusicRNN/weights/weights.ckpt\n",
            "Getting Batches...\n",
            "Training...\n",
            "Calculating Accuracy...\n",
            "Calculating Loss...\n",
            "Iteration 2505\n",
            "Accuracy  0.9453125\n",
            "Loss      0.19811642\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Getting Batches...\n",
            "Training...\n",
            "Calculating Accuracy...\n",
            "Calculating Loss...\n",
            "Iteration 2506\n",
            "Accuracy  0.9453125\n",
            "Loss      0.24367589\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Getting Batches...\n",
            "Training...\n",
            "Calculating Accuracy...\n",
            "Calculating Loss...\n",
            "Iteration 2507\n",
            "Accuracy  0.953125\n",
            "Loss      0.1465352\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Getting Batches...\n",
            "Training...\n",
            "Calculating Accuracy...\n",
            "Calculating Loss...\n",
            "Iteration 2508\n",
            "Accuracy  0.9375\n",
            "Loss      0.20846185\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "/content/drive/My Drive/Programming/rnn/MusicRNN/weights/weights.ckpt\n",
            "Getting Batches...\n",
            "Training...\n",
            "Calculating Accuracy...\n",
            "Calculating Loss...\n",
            "Iteration 2509\n",
            "Accuracy  0.9296875\n",
            "Loss      0.29191703\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Getting Batches...\n",
            "Training...\n",
            "Calculating Accuracy...\n",
            "Calculating Loss...\n",
            "Iteration 2510\n",
            "Accuracy  0.96875\n",
            "Loss      0.1843465\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Getting Batches...\n",
            "Training...\n",
            "Calculating Accuracy...\n",
            "Calculating Loss...\n",
            "Iteration 2511\n",
            "Accuracy  0.9765625\n",
            "Loss      0.1545931\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Getting Batches...\n",
            "Training...\n",
            "Calculating Accuracy...\n",
            "Calculating Loss...\n",
            "Iteration 2512\n",
            "Accuracy  0.9609375\n",
            "Loss      0.1626293\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "/content/drive/My Drive/Programming/rnn/MusicRNN/weights/weights.ckpt\n",
            "Getting Batches...\n",
            "Training...\n",
            "Calculating Accuracy...\n",
            "Calculating Loss...\n",
            "Iteration 2513\n",
            "Accuracy  0.9765625\n",
            "Loss      0.19046909\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Getting Batches...\n",
            "Training...\n",
            "Calculating Accuracy...\n",
            "Calculating Loss...\n",
            "Iteration 2514\n",
            "Accuracy  0.9765625\n",
            "Loss      0.16885541\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Getting Batches...\n",
            "Training...\n",
            "Calculating Accuracy...\n",
            "Calculating Loss...\n",
            "Iteration 2515\n",
            "Accuracy  0.921875\n",
            "Loss      0.26634127\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Getting Batches...\n",
            "Training...\n",
            "Calculating Accuracy...\n",
            "Calculating Loss...\n",
            "Iteration 2516\n",
            "Accuracy  0.96875\n",
            "Loss      0.14903647\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "/content/drive/My Drive/Programming/rnn/MusicRNN/weights/weights.ckpt\n",
            "Getting Batches...\n",
            "Training...\n",
            "Calculating Accuracy...\n",
            "Calculating Loss...\n",
            "Iteration 2517\n",
            "Accuracy  0.921875\n",
            "Loss      0.2455596\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Getting Batches...\n",
            "Training...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dNBe1G7wDZf",
        "colab_type": "text"
      },
      "source": [
        "# Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLDCK7Nkrecq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib import rnn\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "from random import randint\n",
        "#from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "#Vars\n",
        "#mnist=input_data.read_data_sets(\"/tmp/data/\",one_hot=True)\n",
        "steps = 64\n",
        "n_hidden = 1024\n",
        "n_layers = 1\n",
        "n_input = 129\n",
        "learning_rate = 0.0001\n",
        "n_classes = 129\n",
        "batch_size = 2048\n",
        "iterations = 4000\n",
        "beam_width = 2\n",
        "cbeam = 0\n",
        "currentpath = \"/content/drive/My Drive/Programming/rnn/MusicRNN/\"\n",
        "textfile = open(currentpath + \"/midis/text.txt\", \"r\")\n",
        "filecont = list(map(int, textfile.read().replace(\"\\n\", \"128 \").split()))\n",
        "outfile = open(currentpath + \"output.txt\", \"w\")\n",
        "let = steps\n",
        "seed = []\n",
        "rawseed = []\n",
        "paths = [[0]] * beam_width\n",
        "pathsref = [[0]] * beam_width\n",
        "\n",
        "tf.reset_default_graph()\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "        \n",
        "#FUNCTIONS\n",
        "#Structure of NN\n",
        "class RNN:\n",
        "    def __init__(self, units, goIn, weights, biases):\n",
        "        self.lstm_layer = rnn.MultiRNNCell([rnn.BasicLSTMCell(units) for i in range(n_layers)])\n",
        "        self.outputs, self.state = rnn.static_rnn(self.lstm_layer, goIn, dtype = \"float32\")\n",
        "        for i in range(n_layers-1):\n",
        "            self.outputs = [tf.nn.relu(tf.matmul(self.outputs[j], weights[\"hid\"][i]) + biases[\"hid\"][i]) for j in range(len(self.outputs))]\n",
        "            self.outputs = tf.nn.dropout(self.outputs, keep_prob)\n",
        "    def p(self, x, keep_prob):\n",
        "        return tf.matmul(self.outputs[x], weights[\"out\"][0]) + biases[\"out\"][0]\n",
        "\n",
        "def charnum(c):\n",
        "    if c == \"\\n\":\n",
        "        return 128\n",
        "    else:\n",
        "        return int(c)\n",
        "\n",
        "def numchar(c):\n",
        "    if c == 128:\n",
        "        return \"\\n\"\n",
        "    else:\n",
        "        return str(c) + \" \"\n",
        "\n",
        "def numtolst(n):\n",
        "    lst = [0] * n_input\n",
        "    lst[n] = 1\n",
        "    return lst\n",
        "\n",
        "def skewedrandom():\n",
        "    ret = randint(0, beam_width-1)\n",
        "    return ret\n",
        "\n",
        "def getBatch():\n",
        "    return np.asarray(seed)\n",
        "\n",
        "\n",
        "seedstart = randint(10000, 50000)\n",
        "\n",
        "for i in range(steps):\n",
        "    seed.append(numtolst(charnum(filecont[i + seedstart])))\n",
        "    rawseed.append(filecont[i + seedstart])\n",
        "\n",
        "weights = {\n",
        "    \"hid\" : [tf.Variable(tf.random_normal([n_hidden, n_hidden])), tf.Variable(tf.random_normal([n_hidden, n_hidden])),\n",
        "             tf.Variable(tf.random_normal([n_hidden, n_hidden])), tf.Variable(tf.random_normal([n_hidden, n_hidden]))],\n",
        "    \"out\" : [tf.Variable(tf.random_normal([n_hidden, n_classes]))]\n",
        "}\n",
        "biases = {\n",
        "    \"hid\" : [tf.Variable(tf.random_normal([n_hidden])), tf.Variable(tf.random_normal([n_hidden])),\n",
        "             tf.Variable(tf.random_normal([n_hidden])), tf.Variable(tf.random_normal([n_hidden]))],\n",
        "    \"out\" : [tf.Variable(tf.random_normal([n_classes]))]\n",
        "}\n",
        "\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "inp = tf.placeholder(\"float\", [None, steps, n_input])\n",
        "\n",
        "inpu = tf.unstack(inp, steps, 1)\n",
        "\n",
        "lstm = RNN(n_hidden, inpu, weights, biases)\n",
        "\n",
        "ans_sing = lstm.p(-1, keep_prob)\n",
        "\n",
        "answers = tf.nn.top_k(lstm.p(-1, keep_prob), n_classes)\n",
        "\n",
        "ans_conf = answers[0]\n",
        "ans_val = answers[1]\n",
        "\n",
        "saver = tf.train.Saver(tf.trainable_variables())\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Run NN\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    i = 1\n",
        "    try:\n",
        "        print(\"Loading save\")\n",
        "        saver.restore(sess, currentpath + \"weights/weights.ckpt\")\n",
        "    except:\n",
        "        print(\"No save found\")\n",
        "    for j in range(len(rawseed)):\n",
        "        sys.stdout.write(numchar(rawseed[j]))\n",
        "    sys.stdout.write(\"||\")\n",
        "    while i <= iterations:\n",
        "        if i % 200 == 0:\n",
        "            print(\"Epoch \" + str(i) + \" / \" + str(iterations))\n",
        "        batch_in = getBatch()\n",
        "        batch_in = batch_in.reshape((1, steps, n_input))\n",
        "        pred = sess.run(ans_val, {inp: batch_in, keep_prob: 1})\n",
        "        randomizedpred = pred[0][int(np.absolute(np.random.normal(scale=0.7)))]\n",
        "        seed.pop(0)\n",
        "        seed.append(numtolst(randomizedpred))\n",
        "        #print(pred[0])\n",
        "        sys.stdout.write(numchar(randomizedpred))\n",
        "        outfile.write(numchar(randomizedpred))\n",
        "        i += 1\n",
        "        #Failed Beam Search Implementation below USE AT OWN RISK (ITS KINDA BAD)\n",
        "        '''updc = []\n",
        "        updv = []\n",
        "        kp = 0.9\n",
        "        if cbeam == 0:\n",
        "            batch_in = batch_in.reshape((1, steps, n_input))\n",
        "            fd = {inp: batch_in, keep_prob: kp}\n",
        "            ansv = sess.run(ans_val, fd)[0]\n",
        "            ansc = sess.run(ans_conf, fd)[0]\n",
        "            for j in range(beam_width):\n",
        "                paths[j] = [ansc[j], ansv[j]]\n",
        "        for j in range(beam_width):\n",
        "            batch_in = getBatch()\n",
        "            if cbeam == 0:\n",
        "                break;\n",
        "            for k in range(cbeam):\n",
        "                batch_in = batch_in[1:]\n",
        "            for k in range(cbeam):\n",
        "                batch_in = batch_in.tolist()\n",
        "                batch_in.append(numtolst(pathsref[j][k + 1]))\n",
        "                batch_in = np.array(batch_in)\n",
        "            #print lisnum(batch_in)\n",
        "            batch_in = batch_in.reshape((1, steps, n_input)) #get input\n",
        "            fd = {inp: batch_in, keep_prob: kp}\n",
        "            ansv = sess.run(ans_val, fd)[0]\n",
        "            ansc = sess.run(ans_conf, fd)[0]\n",
        "            for k in range(beam_width):\n",
        "                updc.append(pathsref[j][0] + ansc[k])\n",
        "                updv.append(ansv[k])\n",
        "        \n",
        "        topcs = []\n",
        "        topvs = []\n",
        "        \n",
        "        for j in range(beam_width):\n",
        "            if cbeam == 0:\n",
        "                break;\n",
        "            topc = 0\n",
        "            topv = 0\n",
        "            topi = 0\n",
        "            for k in range(beam_width):\n",
        "                if updc[k] > topc:\n",
        "                    topc = updc[k]\n",
        "                    topv = updv[k]\n",
        "                    topi = k\n",
        "            topcs.append(topc)\n",
        "            topvs.append(topv)\n",
        "            temp = [topc]\n",
        "            for k in range(cbeam):\n",
        "                temp.append(pathsref[j][k+1])\n",
        "            temp.append(topv)\n",
        "            paths[j] = temp\n",
        "            updc.pop(topi)\n",
        "            updv.pop(topi)\n",
        "        \n",
        "        i += 1 \n",
        "        cbeam += 1\n",
        "        pathsref = paths\n",
        "        if cbeam >= beam_width:\n",
        "            ind = skewedrandom()\n",
        "            print(\"IND: \" + str(ind))\n",
        "            for j in range(beam_width):\n",
        "                printer = \"\"\n",
        "                if j == 0:\n",
        "                    printer = paths[ind][j + 1]\n",
        "                else:\n",
        "                    printer = paths[ind][j + 1]\n",
        "                seed.pop(0)\n",
        "                seed.append(numtolst(paths[ind][j + 1]))\n",
        "                sys.stdout.write(numchar(paths[ind][j + 1]))\n",
        "                outfile.write(numchar(paths[ind][j + 1]))\n",
        "            paths = [[0]] * beam_width\n",
        "            pathsref = [[0]] * beam_width\n",
        "            cbeam = 0'''\n",
        "outfile.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wLb3bHMNK_I",
        "colab_type": "text"
      },
      "source": [
        "# Clean Up Output File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6BZ6Dw1NSBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "rfile = \"/content/drive/My Drive/Programming/rnn/MusicRNN/output\"\n",
        "rfilebk = \"/content/drive/My\\ Drive/Programming/rnn/MusicRNN/output\"\n",
        "\n",
        "infile = open(rfile + \".txt\", \"r\")\n",
        "outfile = open(rfile + \".tmp.txt\", \"w+\")\n",
        "\n",
        "for note in infile:\n",
        "    line = note.split(\" \")\n",
        "    line = line[:-1]\n",
        "    already = []\n",
        "    if len(line) == 0:\n",
        "        outfile.write(\"\\n\")\n",
        "        continue\n",
        "    for i in line:\n",
        "        if i in already:\n",
        "            continue\n",
        "        if not i.isdigit():\n",
        "            continue\n",
        "        already.append(i)\n",
        "    already.sort()\n",
        "    for i in already:\n",
        "        outfile.write(i + \" \")\n",
        "    outfile.write(\"\\n\")\n",
        "outfile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvOXOIsHvxsO",
        "colab_type": "text"
      },
      "source": [
        "# Convert From Text To Midi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGctWHBYp3i0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from time import sleep\n",
        "\n",
        "rfile = \"/content/drive/My Drive/Programming/rnn/MusicRNN/output\"\n",
        "rfilebk = \"/content/drive/My\\ Drive/Programming/rnn/MusicRNN/output\"\n",
        "\n",
        "ninterval = 140\n",
        "\n",
        "infile = open(rfile + \".tmp.txt\", \"r\")\n",
        "outfile = open(rfile + \".tmp\", \"w+\")\n",
        "outfile.write(\"0, 0, Header, 0, 1, 384\\n\")\n",
        "outfile.write(\"1, 0, Start_track\\n\")\n",
        "outfile.write('1, 0, Title_t, \"Starttrack\"\\n')\n",
        "outfile.write(\"1, 0, Time_signature, 4, 2, 24, 8\\n\")\n",
        "outfile.write(\"1, 0, Tempo, 600000\\n\")\n",
        "outfile.write(\"1, 0, Program_c, 1, 0\\n\")\n",
        "outfile.write('1, 0, Instrument_name_t, \"ahsdfhalisudhgaliughlu\"\\n')\n",
        "time = -ninterval\n",
        "prev = []\n",
        "ons = 0\n",
        "ofs = 0\n",
        "for note in infile:\n",
        "    time += ninterval\n",
        "    line = note.split(\" \")\n",
        "    line = line[:-1]\n",
        "    already = []\n",
        "    if len(line) == 0:\n",
        "        continue\n",
        "    for i in prev:\n",
        "        if not i.isdigit():\n",
        "            continue\n",
        "        isDel = True\n",
        "        for j in line:\n",
        "            if not j.isdigit():\n",
        "                continue\n",
        "            if i == j:\n",
        "                isDel = False\n",
        "                break\n",
        "        if isDel:\n",
        "            outfile.write(\"1, \" + str(time) + \", Note_off_c, 1, \" + str(i) + \", 0\\n\")\n",
        "            ofs += 1\n",
        "    for i in line:\n",
        "        if i in already:\n",
        "            continue\n",
        "        if not i.isdigit():\n",
        "            continue\n",
        "        isNew = True\n",
        "        already.append(i)\n",
        "        for j in prev:\n",
        "            if not j.isdigit():\n",
        "                continue\n",
        "            if i == j:\n",
        "                isNew = False\n",
        "                break\n",
        "        if isNew:\n",
        "            outfile.write(\"1, \" + str(time) + \", Note_on_c, 1, \" + str(i) + \", 127\\n\")\n",
        "            ons += 1\n",
        "    prev = already\n",
        "for i in prev:\n",
        "    if not i.isdigit():\n",
        "        continue\n",
        "    outfile.write(\"1, \" + str(time) + \", Note_off_c, 1, \" + str(i) + \", 0\\n\")\n",
        "    ofs += 1\n",
        "print(ons)\n",
        "print(ofs)\n",
        "outfile.write(\"1, \" + str(time) + \", End_track\\n\")\n",
        "outfile.write(\"0, 0, End_of_file\\n\")\n",
        "outfile.close()\n",
        "print(os.popen(\"csvmidi \" + rfilebk + \".tmp > \" + rfilebk + \"out.mid\").read())\n",
        "sleep(1)\n",
        "print(os.popen(\"timidity -Ow '\" + rfile + \"out.mid'\").read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoZHrNGKvrcB",
        "colab_type": "text"
      },
      "source": [
        "# Convert From Midi To Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOPBbpolTyR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls /content/drive/My\\ Drive/Programming/rnn/MusicRNN/midis/*.mid -1 | wc -l\n",
        "#Convert midi to txt\n",
        "import os\n",
        "\n",
        "rootdirnobk = \"/content/drive/My Drive/Programming/rnn/MusicRNN/midis/\"\n",
        "rootdiryebk = \"/content/drive/My\\ Drive/Programming/rnn/MusicRNN/midis/\"\n",
        "\n",
        "files = int(os.popen(\"ls \" + rootdiryebk + \"*.mid -1 | wc -l\").read())\n",
        "\n",
        "print(files)\n",
        "\n",
        "songs = []\n",
        "\n",
        "for i in range(files):\n",
        "    print(\"READING \" + str(i))\n",
        "    try:\n",
        "        songs.append(os.popen(\"midicsv \" + rootdiryebk + str(i) + \".mid\").read())\n",
        "    except:\n",
        "        print(\"BAD\" + str(i))\n",
        "\n",
        "shuffle(songs)\n",
        "\n",
        "print(songs[0])\n",
        "\n",
        "outfile = open(rootdirnobk + \"text.txt\", \"w+\")\n",
        "\n",
        "for i in range(len(songs)):\n",
        "    #outfile.write(\"[SONG # \" + str(i) + \"]\")\n",
        "    notes = [0] * 128\n",
        "    out = \"\"\n",
        "    \n",
        "    csong = songs[i].split(\"\\n\")\n",
        "    final = 0\n",
        "    stop = len(csong)\n",
        "    ret = \"\"\n",
        "    ptime = 0\n",
        "    div = 1\n",
        "    for j in range(stop):\n",
        "        words = csong[j].split(\", \");\n",
        "        if len(words) < 3:\n",
        "            continue\n",
        "        if words[2] == \"Tempo\":\n",
        "            div = int(words[3]) / 10000\n",
        "    for j in range(stop):\n",
        "        words = csong[j].split(\", \");\n",
        "        if len(words) < 3:\n",
        "            continue\n",
        "        if words[2] == \"Note_off_c\" or words[2] == \"Note_on_c\":\n",
        "            final = max(final, int(words[1]))\n",
        "    time = [\"\"] * int((final+1) / div)\n",
        "    for j in range(stop):\n",
        "        n = 0\n",
        "        words = csong[j].split(\", \");\n",
        "        if len(words) < 3:\n",
        "            continue\n",
        "        \n",
        "        if words[2] == \"Note_off_c\" or words[2] == \"Note_on_c\":\n",
        "            for k in range(len(notes)):\n",
        "                if notes[k] == 1:\n",
        "                    for l in range(int(ptime / div), int(int(words[1]) / div)):\n",
        "                        time[l] += str(k) + \" \"\n",
        "            ptime = int(words[1])\n",
        "        if words[2] == \"Note_on_c\":\n",
        "            notes[int(words[4])] = 1\n",
        "        if words[2] == \"Note_off_c\":\n",
        "            notes[int(words[4])] = 0\n",
        "    toolong = False\n",
        "    for j in range(len(time)):\n",
        "        outline = time[j].split(\" \")\n",
        "        if(len(outline) > 10):\n",
        "            toolong = True\n",
        "            print(\"OMIT: \" + str(i))\n",
        "            break\n",
        "    if toolong:\n",
        "        continue\n",
        "    for j in range(len(time)):\n",
        "        outfile.write(time[j] + \"\\n\")\n",
        "outfile.close()\n",
        "print(\"done\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}